{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "id": "THO5qRxkhCKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv('/Dataset/Labelled/EA_Labelled.csv',encoding='unicode-escape')"
      ],
      "metadata": {
        "id": "4l_LnLrjhI7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "examples1=df['Sentences'].tolist()"
      ],
      "metadata": {
        "id": "WQCsRWABhm-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "falcon_pred=[]"
      ],
      "metadata": {
        "id": "Yvbuq7MBDMBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import transformers\n",
        "import torch\n",
        "import pandas as pd\n",
        "pip install transformers\n",
        "\n",
        "model = \"tiiuae/falcon-40b\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model)\n",
        "pipeline = transformers.pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    trust_remote_code=True,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "for sentence in examples1:\n",
        "    sequences = pipeline(\n",
        "        sentence,\n",
        "        max_length=200,\n",
        "        do_sample=True,\n",
        "        top_k=10,\n",
        "        num_return_sequences=1,\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "    )\n",
        "\n",
        "    for seq in sequences:\n",
        "        output= seq['generated_text']\n",
        "    falcon_pred.append(output)\n",
        "\n"
      ],
      "metadata": {
        "id": "9uVrut6TBBp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "master_list_df=pd.DataFrame(falcon_pred,columns=['Falcon_Output'])\n",
        "master_list_df.to_csv('Falcon_Output.csv', index=False)"
      ],
      "metadata": {
        "id": "Nf5BrMl0BBdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cMBEVww-846-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pZsxT35nhoEi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}